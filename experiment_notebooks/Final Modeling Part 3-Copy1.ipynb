{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental Health Hazards and Population Characteristic Modeling\n",
    "**Author: Jaclyn Dwyer**\n",
    "\n",
    "**Project Goal**: The goal of this project is to predict percentage of Low Birth Weights based on California census tracts' environmental health hazard factors in order to determine how to allocate resources for low birth weight newborns in CA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous modeling notebook, models were created in order to obtain the best predictions for percentage of LBW based off of environmental health hazards. For this second part of modeling, in order to try and obtain even more accurate predictions, population characteristics are added to the data. The results of these models are compared to the THE BEST MODEL FROM BEFORE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import combinations\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "%matplotlib inline\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "df18 = pd.read_csv('data/merged/df18')\n",
    "\n",
    "#drop Unamed\n",
    "df18.drop(columns = ['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental Health Hazard  and Population Characteristic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some final data preparation is done before running our models including creating dummy variables and dropping columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_population</th>\n",
       "      <th>california_county</th>\n",
       "      <th>sb_535_disadvantaged</th>\n",
       "      <th>ozone</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>diesel_pm</th>\n",
       "      <th>drinking_water</th>\n",
       "      <th>pesticides</th>\n",
       "      <th>tox_release</th>\n",
       "      <th>traffic</th>\n",
       "      <th>cleanup_sites</th>\n",
       "      <th>groundwater_threats</th>\n",
       "      <th>haz_waste</th>\n",
       "      <th>imp_water_bodies</th>\n",
       "      <th>solid_waste</th>\n",
       "      <th>pollution_burden_score</th>\n",
       "      <th>lbw</th>\n",
       "      <th>education</th>\n",
       "      <th>linguistic_isolation</th>\n",
       "      <th>unemployment</th>\n",
       "      <th>housing_burden</th>\n",
       "      <th>Pop. Char. Score</th>\n",
       "      <th>less_10_yrs</th>\n",
       "      <th>yrs_11_64</th>\n",
       "      <th>greater_65</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>white</th>\n",
       "      <th>african_american</th>\n",
       "      <th>native_american</th>\n",
       "      <th>asian_american</th>\n",
       "      <th>other</th>\n",
       "      <th>prev_ozone</th>\n",
       "      <th>prev_pm2_5</th>\n",
       "      <th>prev_diesel_pm</th>\n",
       "      <th>prev_drinking_water</th>\n",
       "      <th>prev_tox_release</th>\n",
       "      <th>prev_traffic</th>\n",
       "      <th>prev_groundwater_threats</th>\n",
       "      <th>prev_haz_waste</th>\n",
       "      <th>prev_imp_water_bodies</th>\n",
       "      <th>prev_solid_waste</th>\n",
       "      <th>prev_lbw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3174</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.40</td>\n",
       "      <td>48.524</td>\n",
       "      <td>681.20</td>\n",
       "      <td>2.75</td>\n",
       "      <td>18551.957190</td>\n",
       "      <td>909.14</td>\n",
       "      <td>80.5</td>\n",
       "      <td>45.75</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0</td>\n",
       "      <td>21.75</td>\n",
       "      <td>9.85</td>\n",
       "      <td>7.44</td>\n",
       "      <td>53.3</td>\n",
       "      <td>16.2</td>\n",
       "      <td>17.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.55</td>\n",
       "      <td>18.8</td>\n",
       "      <td>73.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>65.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.255228</td>\n",
       "      <td>14.746087</td>\n",
       "      <td>44.23</td>\n",
       "      <td>519.882370</td>\n",
       "      <td>96414.458370</td>\n",
       "      <td>1217.535680</td>\n",
       "      <td>55.75</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.80253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6133</td>\n",
       "      <td>San Bernardino</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.062</td>\n",
       "      <td>13.31</td>\n",
       "      <td>38.556</td>\n",
       "      <td>904.66</td>\n",
       "      <td>1.37</td>\n",
       "      <td>7494.236622</td>\n",
       "      <td>782.26</td>\n",
       "      <td>66.2</td>\n",
       "      <td>36.00</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>12.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.04</td>\n",
       "      <td>53.3</td>\n",
       "      <td>33.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>34.1</td>\n",
       "      <td>9.07</td>\n",
       "      <td>19.7</td>\n",
       "      <td>76.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>91.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.465401</td>\n",
       "      <td>13.888224</td>\n",
       "      <td>47.08</td>\n",
       "      <td>604.311803</td>\n",
       "      <td>8122.687693</td>\n",
       "      <td>1232.874128</td>\n",
       "      <td>49.00</td>\n",
       "      <td>1.845</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.38952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_population california_county sb_535_disadvantaged  ozone  pm2_5  \\\n",
       "0              3174           Fresno                   Yes  0.065  15.40   \n",
       "1              6133    San Bernardino                  Yes  0.062  13.31   \n",
       "\n",
       "   diesel_pm  drinking_water  pesticides   tox_release  traffic  \\\n",
       "0     48.524          681.20        2.75  18551.957190   909.14   \n",
       "1     38.556          904.66        1.37   7494.236622   782.26   \n",
       "\n",
       "   cleanup_sites  groundwater_threats  haz_waste  imp_water_bodies  \\\n",
       "0           80.5                45.75      0.795                 0   \n",
       "1           66.2                36.00      1.250                 5   \n",
       "\n",
       "   solid_waste  pollution_burden_score   lbw  education  linguistic_isolation  \\\n",
       "0        21.75                    9.85  7.44       53.3                  16.2   \n",
       "1        12.00                   10.00  7.04       53.3                  33.4   \n",
       "\n",
       "   unemployment  housing_burden  Pop. Char. Score  less_10_yrs  yrs_11_64  \\\n",
       "0          17.6            26.0              9.55         18.8       73.6   \n",
       "1          12.3            34.1              9.07         19.7       76.1   \n",
       "\n",
       "   greater_65  hispanic  white  african_american  native_american  \\\n",
       "0         7.6      65.3    4.2              24.6              0.5   \n",
       "1         4.2      91.1    5.8               0.7              0.3   \n",
       "\n",
       "   asian_american  other  prev_ozone  prev_pm2_5  prev_diesel_pm  \\\n",
       "0             3.5    1.8    0.255228   14.746087           44.23   \n",
       "1             1.4    0.7    0.465401   13.888224           47.08   \n",
       "\n",
       "   prev_drinking_water  prev_tox_release  prev_traffic  \\\n",
       "0           519.882370      96414.458370   1217.535680   \n",
       "1           604.311803       8122.687693   1232.874128   \n",
       "\n",
       "   prev_groundwater_threats  prev_haz_waste  prev_imp_water_bodies  \\\n",
       "0                     55.75           0.520                      0   \n",
       "1                     49.00           1.845                      5   \n",
       "\n",
       "   prev_solid_waste  prev_lbw  \n",
       "0               5.0   5.80253  \n",
       "1               2.0   6.38952  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df18.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables\n",
    "cc_dummies = pd.get_dummies(df18['california_county'], prefix='cc', drop_first=True)\n",
    "disadvantaged_dummies = pd.get_dummies(df18['sb_535_disadvantaged'], prefix='disadvantaged', drop_first=True)\n",
    "\n",
    "df18 = pd.concat([df18, cc_dummies, disadvantaged_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns\n",
    "df18.drop(columns = ['california_county', 'sb_535_disadvantaged'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df18.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df18_features = df18.drop(columns = 'lbw', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df18_features, \n",
    "                                                    df18['lbw'], \n",
    "                                                    random_state=20, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit to train data\n",
    "\n",
    "#instantiate a linear regression object\n",
    "baseline = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "baseline = baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on train and test set\n",
    "y_train_pred = baseline.predict(X_train)\n",
    "\n",
    "y_test_pred = baseline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give true value and predictions\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('baseline train: ' + str(rmse))\n",
    "print('baseline test: ' + str(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give true value and predictions\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "#give true value and predictions\n",
    "r2_test = r2_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the train and test set are very similar not eliciting any concerns for overfitting. When compared to the results of the baseline model using only environmental health hazards for predictions, the added population characteristics dropped the rmse by about 0.10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactions Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Interactions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try a achieve a lower rmse score, all possible interactions are created as well as cross validations. If the interaction improves the score from the baseline model, the interaction is stored in an interactions list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()\n",
    "\n",
    "X = df18.drop('lbw', axis=1)\n",
    "y = df18['lbw']\n",
    "\n",
    "crossvalidation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(regression, X, y, scoring='neg_root_mean_squared_error', cv=crossvalidation))\n",
    "\n",
    "\n",
    "interactions = []\n",
    "\n",
    "feat_combinations = combinations(X.columns, 2)\n",
    "\n",
    "data = X.copy()\n",
    "for i, (a, b) in enumerate(feat_combinations):\n",
    "    data['interaction'] = data[a] * data[b]\n",
    "    score = np.mean(cross_val_score(regression, data, y, scoring='neg_root_mean_squared_error', cv=crossvalidation))\n",
    "    if score > baseline:\n",
    "        interactions.append((a, b, round(score,3)))\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interaction(i, dataframe, interactions):\n",
    "    new_column = interactions[i][0] + '_and_' + interactions[i][1]\n",
    "    dataframe[new_column] = dataframe[interactions[i][0]] * dataframe[interactions[i][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(interactions)):\n",
    "    create_interaction(i, df18, interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test Split**\n",
    "\n",
    "A second train test split is conducted in order to include the interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df18_features_i = df18.drop(columns = 'lbw', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(df18_features_i, \n",
    "                                                    df18['lbw'], \n",
    "                                                    random_state=20, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Interaction Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit to train data\n",
    "\n",
    "#instantiate a linear regression object\n",
    "interactions = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "interactions = interactions.fit(X_train_i, y_train_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on train and test set\n",
    "y_train_pred_i = interactions.predict(X_train_i)\n",
    "\n",
    "y_test_pred_i = interactions.predict(X_test_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give true value and predictions\n",
    "mse_i = mean_squared_error(y_train_i, y_train_pred_i)\n",
    "rmse_i = np.sqrt(mse_i)\n",
    "\n",
    "#give true value and predictions\n",
    "mse_test_i = mean_squared_error(y_test_i, y_test_pred_i)\n",
    "rmse_test_i = np.sqrt(mse_test_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('baseline train: ' + str(rmse))\n",
    "print('baseline test: ' + str(rmse_test))\n",
    "print('interactions train: ' + str(rmse_i))\n",
    "print('interactions test: ' + str(rmse_test_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same thing that happened after adding all the interactions with the environmental health hazard models happened again here. Adding the interactions resulted in a lowered rmse for the train set. However, the rmse of the test set increased substantially, indicating that the model is overfitted. In order to try and account for overfitting some features are dropped using feature elimination techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select K Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select K best is used in order to try and eliminate some features to account for overfitting and create improved predictions. This model was previously run with a k equal to 300, 220 200, 175, 150, and 100 in order to obtain the best train and test scores. The results are shown in the graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# f, axes = plt.subplots(1, figsize=(15,5))\n",
    "# line = sns.lineplot(x= [300, 220, 200, 175, 150, 100],\n",
    "#                     y=[1.35, 1.37, 1.37, 1.38, 1.39, 1.40])\n",
    "# line2 = sns.lineplot(x= [300, 220, 200, 175, 150, 100],\n",
    "#                     y=[1.82, 1.38, 1.38, 1.38, 1.39, 1.40])\n",
    "# line.axes.set_title(\"Kbest Train vs Test Results\",fontsize=18)\n",
    "# line.set_xlabel(\"K Values\",fontsize=15)\n",
    "# line.set_ylabel(\"Train & Test Scores\",fontsize=15)\n",
    "# #create proxy artist legent\n",
    "# blue_line = mlines.Line2D([], [], color='blue', label='Train')\n",
    "# orange_line = mlines.Line2D([], [], color='orange', label='Test')\n",
    "# line.legend(handles=[blue_line, orange_line]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K value of 175 is selected as any values over 175 start to indicate signs of overfitting. While values less than 175 don't show signs of overfitting the train and test rmse scores start to increase slightly compared to 175."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_regression, k=30)\n",
    "\n",
    "selector.fit(X_train_i, y_train_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.get_support();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_k_columns = X_train_i.columns[selector.get_support()]\n",
    "removed_k_columns = X_train_i.columns[~selector.get_support()]\n",
    "\n",
    "kbest = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "kbest = kbest.fit(X_train_i[selected_k_columns], y_train_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on train and test set\n",
    "y_train_pred_k = kbest.predict(X_train_i[selected_k_columns])\n",
    "\n",
    "y_test_pred_k = kbest.predict(X_test_i[selected_k_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give true value and predictions\n",
    "mse_k = mean_squared_error(y_train_i, y_train_pred_k)\n",
    "rmse_k = np.sqrt(mse_k)\n",
    "\n",
    "#give true value and predictions\n",
    "mse_test_k = mean_squared_error(y_test_i, y_test_pred_k)\n",
    "rmse_test_k = np.sqrt(mse_test_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('baseline train: ' + str(rmse))\n",
    "print('baseline test: ' + str(rmse_test))\n",
    "print('interactions train: ' + str(rmse_i))\n",
    "print('interactions test: ' + str(rmse_test_i))\n",
    "print('kbest train: ' + str(rmse_k))\n",
    "print('kbest test: ' + str(rmse_test_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60 = tr\n",
    "80 = tr 1.2915929593297197, ts 1.2915929593297197\n",
    "125 = tr 1.2817309715250822, ts 1.3054036846824373\n",
    "150 = tr 1.2786750746699638, ts 1.30426438869419\n",
    "200 = tr 1.2656040212863735, ts 1.3157643142615463"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from the kbest model are show a decrease in the rmse score compared to the baseline model and do not show signs of overfitting as seen in the interactions model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more feature elimination technique is run on the features selected in the kbest model.\n",
    "A best subset of features is created by a process of eliminating underperforming features of a model one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = LinearRegression()\n",
    "# Create recursive feature eliminator that scores features by root mean squared errors\n",
    "rfe = RFECV(estimator=rfe, step=1, cv=7,  scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit recursive feature eliminator \n",
    "rfe.fit(X_train_i[selected__k_columns], y_train_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create variables for features selected for model and removed\n",
    "selected_rfe = X_train_i[selected_k_columns].columns[selector.support_]\n",
    "removed_rfe = X_train_i[selected_k_columns].columns[~selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = LinearRegression()\n",
    "# Create recursive feature eliminator that scores features by mean squared errors\n",
    "selector = RFECV(estimator=ols, step=1, cv=7,  scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit recursive feature eliminator \n",
    "selector.fit(X_train_i[selected_k_columns], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
